{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso ,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(y_pred, file_name):\n",
    "    df = pd.DataFrame(range(1461, 2920), columns=['Id'])\n",
    "    df[\"SalePrice\"] = y_pred\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Predictions saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 54) (1460, 1) (1459, 54)\n"
     ]
    }
   ],
   "source": [
    "x_train= pd.read_csv(\"Xtrain.csv\")\n",
    "y_train=pd.read_csv(\"Ytrain.csv\")\n",
    "x_test= pd.read_csv(\"Xtest.csv\")\n",
    "print(x_train.shape,y_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 981636117.0122207\n",
      "Training RMSE: 31331.072707652715\n",
      "Training R² Score: 0.844352461838888\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_train, model.predict(x_train))\n",
    "rmse = np.sqrt(mse)  \n",
    "r2 = r2_score(y_train, model.predict(x_train)) \n",
    "\n",
    "print(f\"Training MSE: {mse}\")\n",
    "print(f\"Training RMSE: {rmse}\")\n",
    "print(f\"Training R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to tayeb_lr.csv\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_csv(y_pred,\"tayeb_lr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 981636314.6869091\n",
      "Training RMSE: 31331.07586226348\n",
      "Training R² Score: 0.8443524304957273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+11, tolerance: 9.208e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model_l = Lasso()\n",
    "model_l.fit(x_train,y_train)\n",
    "y_pred=model_l.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_train, model_l.predict(x_train))\n",
    "rmse = np.sqrt(mse)  \n",
    "r2 = r2_score(y_train, model_l.predict(x_train)) \n",
    "\n",
    "print(f\"Training MSE: {mse}\")\n",
    "print(f\"Training RMSE: {rmse}\")\n",
    "print(f\"Training R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 981638439.7491994\n",
      "Training RMSE: 31331.109775256915\n",
      "Training R² Score: 0.8443520935473324\n"
     ]
    }
   ],
   "source": [
    "model_ri = Ridge()\n",
    "model_ri.fit(x_train,y_train)\n",
    "y_pred=model_ri.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_train, model_ri.predict(x_train))\n",
    "rmse = np.sqrt(mse)  \n",
    "r2 = r2_score(y_train, model_ri.predict(x_train)) \n",
    "\n",
    "print(f\"Training MSE: {mse}\")\n",
    "print(f\"Training RMSE: {rmse}\")\n",
    "print(f\"Training R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 125264415.75227708\n",
      "Training RMSE: 11192.158672583098\n",
      "Training R² Score: 0.9801381615925311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "model_rf = RandomForestRegressor()\n",
    "\n",
    "model_rf.fit(x_train, y_train)\n",
    "y_pred = model_rf.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_train, model_rf.predict(x_train))\n",
    "rmse = np.sqrt(mse)  \n",
    "r2 = r2_score(y_train, model_rf.predict(x_train)) \n",
    "\n",
    "print(f\"Training MSE: {mse}\")\n",
    "print(f\"Training RMSE: {rmse}\")\n",
    "print(f\"Training R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to tayeb_rf.csv\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_csv(y_pred,\"tayeb_rf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradiant Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE (Gradiant Boosting): 224137131.21572232\n",
      "Training RMSE (Gradiant Boosting): 14971.210078538152\n",
      "Training R² Score (Gradiant Boosting): 0.9644609727783814\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingRegressor()\n",
    "\n",
    "model_gb.fit(x_train, y_train)\n",
    "\n",
    "y_pred_gb = model_gb.predict(x_test)\n",
    "\n",
    "mse_gb = mean_squared_error(y_train, model_gb.predict(x_train))\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "r2_gb = r2_score(y_train, model_gb.predict(x_train))\n",
    "\n",
    "print(f\"Training MSE (Gradiant Boosting): {mse_gb}\")\n",
    "print(f\"Training RMSE (Gradiant Boosting): {rmse_gb}\")\n",
    "print(f\"Training R² Score (Gradiant Boosting): {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to tayeb_gb.csv\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_csv(y_pred_gb,\"tayeb_gb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE (Gradiant Boosting): 4085393.7029643855\n",
      "Training RMSE (Gradiant Boosting): 2021.2356871390298\n",
      "Training R² Score (Gradiant Boosting): 0.9993522228234423\n"
     ]
    }
   ],
   "source": [
    "# the best model so far\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\", \n",
    "    n_estimators=1300,  \n",
    "    learning_rate=0.05,  \n",
    "    max_depth=4,  \n",
    "    subsample=0.8,  \n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb.fit(x_train, y_train)\n",
    "\n",
    "y_pred_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_train, model_xgb.predict(x_train))\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_train, model_xgb.predict(x_train))\n",
    "\n",
    "print(f\"Training MSE (Gradiant Boosting): {mse_xgb}\")\n",
    "print(f\"Training RMSE (Gradiant Boosting): {rmse_xgb}\")\n",
    "print(f\"Training R² Score (Gradiant Boosting): {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to tayeb_xgb.csv\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_csv(y_pred_xgb,\"tayeb_xgb.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
