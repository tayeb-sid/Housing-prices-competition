{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"home-data-for-ml-course\\\\train.csv\")\n",
    "test = pd.read_csv(\"home-data-for-ml-course\\\\test.csv\")\n",
    "train.columns = train.columns.str.strip()\n",
    "test.columns = test.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the id\n",
    "train_ID = train[\"Id\"]\n",
    "test_ID  = test[\"Id\"]\n",
    "y = train.SalePrice\n",
    "\n",
    "#drop ID\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "test[[\"LotFrontage\", \"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"BsmtFullBath\",\"GarageCars\",\"BsmtHalfBath\",\"GarageYrBlt\"]] = test[[\"LotFrontage\", \"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"BsmtFullBath\",\"GarageCars\",\"BsmtHalfBath\",\"GarageYrBlt\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "train[[\"LotFrontage\", \"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"BsmtFullBath\",\"GarageCars\",\"BsmtHalfBath\",\"GarageYrBlt\"]] = train[[\"LotFrontage\", \"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"BsmtFullBath\",\"GarageCars\",\"BsmtHalfBath\",\"GarageYrBlt\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "#group features for preprocessing purpose.\n",
    "categorical_features = [feature for feature in train.columns if train[feature].dtype == \"object\"] \n",
    "\n",
    "nominal_features = [\"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \n",
    "                    \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\",\n",
    "                    \"CentralAir\", 'Electrical',\"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "ordinal_features = [ 'LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',\n",
    "                    'BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish','GarageQual',\n",
    "                    'GarageCond','PavedDrive','PoolQC','Fence']\n",
    "\n",
    "numerical_features = [feature for feature in train.columns if feature not in categorical_features + ['SalePrice']]\n",
    "\n",
    "discrete_numerical = [ 'OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','MoSold', \"MSSubClass\"] \n",
    "\n",
    "continuous_numerical = ['LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2',\n",
    "                                  'BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageYrBlt',\n",
    "                                  'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea',\n",
    "                                  'MiscVal','YrSold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # Initialize KNN Imputer (default K=5)\n",
    "# knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# # Apply to numerical features\n",
    "# train[train_numerical] = knn_imputer.fit_transform(train[train_numerical])\n",
    "# test[test_numerical] = knn_imputer.transform(test[test_numerical])\n",
    "\n",
    "# print(\"✅ KNN Imputation applied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "# iter_imputer = IterativeImputer(max_iter=10, random_state=42)  # Uses ML to predict missing values\n",
    "\n",
    "# train[numerical_features] = iter_imputer.fit_transform(train[numerical_features])\n",
    "# test[numerical_features] = iter_imputer.transform(test[numerical_features])\n",
    "\n",
    "# print(\"✅ Iterative Imputation applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Constant Value Imputation applied successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fill Numerical Features with 0\n",
    "train[numerical_features] = train[numerical_features].fillna(0)\n",
    "test[numerical_features] = test[numerical_features].fillna(0)\n",
    "\n",
    "# Fill Categorical Features with \"Do_not_have_this_feature\"\n",
    "train[categorical_features] = train[categorical_features].fillna(\"NA\")\n",
    "test[categorical_features] = test[categorical_features].fillna(\"NA\")\n",
    "\n",
    "print(\"✅ Constant Value Imputation applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you're working with the 'train' DataFrame\n",
    "train[\"Lack_of_feature_index\"] = train[[\"Street\", \"Alley\", \"MasVnrType\", \"GarageType\", \"MiscFeature\", 'BsmtQual',\n",
    "                                        'FireplaceQu', 'PoolQC', 'Fence']].isnull().sum(axis=1) + (train[\"MasVnrType\"] == 'None') + (train[\"CentralAir\"] == 'No')\n",
    "\n",
    "train[\"MiscFeatureExtended\"] = (train[\"PoolQC\"].notnull() * 1 + train[\"MiscFeature\"].notnull() * 1 + train[\"Fence\"].notnull() * 1).astype('int64')\n",
    "\n",
    "train[\"Has_Alley\"] = train[\"Alley\"].notnull().astype('int64')\n",
    "\n",
    "train[\"Lot_occupation\"] = train[\"GrLivArea\"] / train[\"LotArea\"]\n",
    "\n",
    "train[\"Number_of_floors\"] = (train[\"TotalBsmtSF\"] != 0).astype('int64') + (train[\"1stFlrSF\"] != 0).astype('int64') + (train[\"2ndFlrSF\"] != 0).astype('int64')\n",
    "\n",
    "train['Total_Close_Live_Area'] = train['GrLivArea'] + train['TotalBsmtSF']\n",
    "\n",
    "train['Outside_live_area'] = train['WoodDeckSF'] + train['OpenPorchSF'] + train['EnclosedPorch'] + train['3SsnPorch'] + train['ScreenPorch']\n",
    "\n",
    "train['Total_usable_area'] = train['Total_Close_Live_Area'] + train['Outside_live_area']\n",
    "\n",
    "train['Area_Quality_Indicator'] = train['Total_usable_area'] * train['OverallQual']\n",
    "\n",
    "train['Area_Qual_Cond_Indicator'] = train['Total_usable_area'] * train['OverallQual'] * train['OverallCond']\n",
    "\n",
    "train['TotalBath'] = (train['FullBath'] + (0.5 * train['HalfBath']) + train['BsmtFullBath'] + (0.5 * train['BsmtHalfBath']))\n",
    "\n",
    "train[\"Has_garage\"] = train[\"GarageYrBlt\"].notnull().astype('int64')\n",
    "\n",
    "train['House_Age'] = train['YrSold'] - train['YearBuilt']\n",
    "\n",
    "train[\"Is_Remodeled\"] = (train[\"YearBuilt\"] != train[\"YearRemodAdd\"]).astype('int64')\n",
    "\n",
    "train['HasBsmt'] = train['BsmtQual'].notnull().astype('int64')\n",
    "\n",
    "train['Quality_conditition'] = train['OverallQual'] * train['OverallCond']\n",
    "\n",
    "train['Quality_conditition_2'] = train['OverallQual'] + train['OverallCond']\n",
    "\n",
    "train['House_Age2'] = train['YrSold'] - train['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you're working with the 'test' DataFrame\n",
    "test[\"Lack_of_feature_index\"] = test[[\"Street\", \"Alley\", \"MasVnrType\", \"GarageType\", \"MiscFeature\", 'BsmtQual',\n",
    "                                        'FireplaceQu', 'PoolQC', 'Fence']].isnull().sum(axis=1) + (test[\"MasVnrType\"] == 'None') + (test[\"CentralAir\"] == 'No')\n",
    "\n",
    "test[\"MiscFeatureExtended\"] = (test[\"PoolQC\"].notnull() * 1 + test[\"MiscFeature\"].notnull() * 1 + test[\"Fence\"].notnull() * 1).astype('int64')\n",
    "\n",
    "test[\"Has_Alley\"] = test[\"Alley\"].notnull().astype('int64')\n",
    "\n",
    "test[\"Lot_occupation\"] = test[\"GrLivArea\"] / test[\"LotArea\"]\n",
    "\n",
    "test[\"Number_of_floors\"] = (test[\"TotalBsmtSF\"] != 0).astype('int64') + (test[\"1stFlrSF\"] != 0).astype('int64') + (test[\"2ndFlrSF\"] != 0).astype('int64')\n",
    "\n",
    "test['Total_Close_Live_Area'] = test['GrLivArea'] + test['TotalBsmtSF']\n",
    "\n",
    "test['Outside_live_area'] = test['WoodDeckSF'] + test['OpenPorchSF'] + test['EnclosedPorch'] + test['3SsnPorch'] + test['ScreenPorch']\n",
    "\n",
    "test['Total_usable_area'] = test['Total_Close_Live_Area'] + test['Outside_live_area']\n",
    "\n",
    "test['Area_Quality_Indicator'] = test['Total_usable_area'] * test['OverallQual']\n",
    "\n",
    "test['Area_Qual_Cond_Indicator'] = test['Total_usable_area'] * test['OverallQual'] * test['OverallCond']\n",
    "\n",
    "test['TotalBath'] = (test['FullBath'] + (0.5 * test['HalfBath']) + test['BsmtFullBath'] + (0.5 * test['BsmtHalfBath']))\n",
    "\n",
    "test[\"Has_garage\"] = test[\"GarageYrBlt\"].notnull().astype('int64')\n",
    "\n",
    "test['House_Age'] = test['YrSold'] - test['YearBuilt']\n",
    "\n",
    "test[\"Is_Remodeled\"] = (test[\"YearBuilt\"] != test[\"YearRemodAdd\"]).astype('int64')\n",
    "\n",
    "test['HasBsmt'] = test['BsmtQual'].notnull().astype('int64')\n",
    "\n",
    "test['Quality_conditition'] = test['OverallQual'] * test['OverallCond']\n",
    "\n",
    "test['Quality_conditition_2'] = test['OverallQual'] + test['OverallCond']\n",
    "\n",
    "test['House_Age2'] = test['YrSold'] - test['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers based on observations on scatter plots against SalePrice:\n",
    "train = train.drop(train['LotFrontage']\n",
    "                                     [train['LotFrontage']>200].index)\n",
    "train = train.drop(train['LotArea']\n",
    "                                     [train['LotArea']>100000].index)\n",
    "train = train.drop(train['BsmtFinSF1']\n",
    "                                     [train['BsmtFinSF1']>4000].index)\n",
    "train = train.drop(train['TotalBsmtSF']\n",
    "                                     [train['TotalBsmtSF']>6000].index)\n",
    "train = train.drop(train['1stFlrSF']\n",
    "                                     [train['1stFlrSF']>4000].index)\n",
    "train = train.drop(train.GrLivArea\n",
    "                                     [(train['GrLivArea']>4000) & \n",
    "                                      (y<300000)].index)\n",
    "train = train.drop(train.LowQualFinSF\n",
    "                                     [train['LowQualFinSF']>550].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ordinal encoding applied successfully!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Define ordinal mapping correctly\n",
    "ordinal_mapping = {\n",
    "    \"GarageQual\" : {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "    \"Fence\" : {'GdPrv': 4,'MnPrv': 3,'GdWo': 2, 'MnWw': 1,'NA': 0},\n",
    "    \"GarageFinish\" : {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0},\n",
    "    \"KitchenQual\": {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "    \"GarageCond\" : {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "    \"HeatingQC\" : {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "    \"ExterQual\" : {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "    \"BsmtCond\": {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "    \"LandSlope\": {'Gtl': 2, 'Mod': 1, 'Sev': 0},\n",
    "    \"ExterCond\" : {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0},\n",
    "    \"BsmtExposure\" : {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0},\n",
    "    \"PavedDrive\":  {'Y': 2, 'P': 1, 'N': 0},\n",
    "    \"BsmtQual\" : {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "    \"LotShape\" : {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0},\n",
    "    \"BsmtFinType2\" : {'GLQ': 6,'ALQ': 5,'BLQ': 4,'Rec': 3,'LwQ': 2,'Unf': 1, 'NA': 0},\n",
    "    \"BsmtFinType1\" : {'GLQ': 6,'ALQ': 5,'BLQ': 4,'Rec': 3,'LwQ': 2,'Unf': 1, 'NA': 0},\n",
    "    \"FireplaceQu\" : {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0},\n",
    "    \"Utilities\" : {\"AllPub\":3, \"NoSewr\":2, \"NoSeWa\":1,  \"ELO\":0},\n",
    "    \"Functional\" : {'Typ': 7,'Min1': 6,'Min2': 5,'Mod': 4,'Maj1': 3,'Maj2': 2, 'Sev': 1 , 'Sal': 0},\n",
    "    \"PoolQC\" : {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "}\n",
    "\n",
    "# ✅ Extract the ordinal feature names\n",
    "ordinal_cols = list(ordinal_mapping.keys())\n",
    "train[ordinal_cols] = train[ordinal_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# ✅ Create an OrdinalEncoder with the correct category order\n",
    "encoder = OrdinalEncoder(\n",
    "    categories=[list(ordinal_mapping[col].keys()) for col in ordinal_cols],\n",
    "    handle_unknown=\"use_encoded_value\",  # Avoid errors for unseen categories\n",
    "    unknown_value=-1  # Assign unknown categories as -1\n",
    ")\n",
    "train[ordinal_cols] = train[ordinal_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# ✅ Apply ordinal encoding to both datasets\n",
    "train[ordinal_cols] = encoder.fit_transform(train[ordinal_cols])\n",
    "test[ordinal_cols] = encoder.transform(test[ordinal_cols])\n",
    "\n",
    "print(\"✅ Ordinal encoding applied successfully!\")\n",
    "train.replace(-1, 0, inplace=True)\n",
    "test.replace(-1, 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train & Test now have the same OHE features using `OneHotEncoder()`\n",
      "New shape of TEST dataset: (1459, 244)\n",
      "New shape of TRAIN dataset: (1452, 245)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# Fit on train data, then transform both train & test\n",
    "train_encoded = encoder.fit_transform(train[nominal_features])\n",
    "test_encoded = encoder.transform(test[nominal_features])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "train_encoded = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(nominal_features), index=train.index)\n",
    "test_encoded = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(nominal_features), index=test.index)\n",
    "\n",
    "# Drop original categorical features and replace with OHE\n",
    "train = train.drop(columns=nominal_features).join(train_encoded)\n",
    "test = test.drop(columns=nominal_features).join(test_encoded)\n",
    "\n",
    "print(\"train & Test now have the same OHE features using `OneHotEncoder()`\")\n",
    "print(\"New shape of TEST dataset:\", test.shape)\n",
    "print(\"New shape of TRAIN dataset:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛑 Features in test but NOT in train: set()\n"
     ]
    }
   ],
   "source": [
    "extra_test_features = set(test.columns) - set(train.columns)\n",
    "print(\"🛑 Features in test but NOT in train:\", extra_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated numerical features:\n",
      " ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice', 'MiscFeatureExtended', 'TotalBath', 'HasBsmt']\n"
     ]
    }
   ],
   "source": [
    "# Identify all numerical features after encoding\n",
    "train_numerical = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Exclude ordinal features (since they were manually mapped but remain categorical)\n",
    "train_numerical = [col for col in train_numerical if col not in ordinal_mapping.keys()]\n",
    "train_numerical = [col for col in train_numerical if \"_\" not in col]\n",
    "\n",
    "print(\"✅ Updated numerical features:\\n\", train_numerical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated numerical features:\n",
      " ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'MiscFeatureExtended', 'TotalBath', 'HasBsmt']\n"
     ]
    }
   ],
   "source": [
    "# Identify all numerical features after encoding\n",
    "test_numerical = test.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Exclude ordinal features (since they were manually mapped but remain categorical)\n",
    "test_numerical = [col for col in test_numerical if col not in ordinal_mapping.keys()]\n",
    "test_numerical = [col for col in test_numerical if \"_\" not in col]\n",
    "\n",
    "print(\"✅ Updated numerical features:\\n\", test_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoders = {}\n",
    "# for col in nominal_features:\n",
    "#     le = LabelEncoder()\n",
    "#     train[col] = le.fit_transform(train[col].astype(str))\n",
    "#     test[col] = le.fit_transform(test[col].astype(str))\n",
    "\n",
    "#     label_encoders[col]= le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute skewness for each numerical feature\n",
    "# skewness = train[train_numerical].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "\n",
    "# # Set threshold for skewness\n",
    "# skew_threshold = 0.75\n",
    "\n",
    "# # Get highly skewed features\n",
    "# highly_skewed = skewness[(skewness > skew_threshold) & (skewness.index != \"SalePrice\")]\n",
    "# print(f\"🔍 Found {len(highly_skewed)} highly skewed features:\\n\", highly_skewed)\n",
    "\n",
    "# # Apply Yeo-Johnson transformation\n",
    "# pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "# train[highly_skewed.index] = pt.fit_transform(train[highly_skewed.index])\n",
    "\n",
    "# print(\"✅ Yeo-Johnson transformation applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check skewness after transformation\n",
    "# new_skewness = train[highly_skewed.index].apply(lambda x: x.skew())\n",
    "# print(\"📉 Skewness after transformation:\\n\", new_skewness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization applied.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_features = [col for col in train_numerical if col != \"SalePrice\"]\n",
    "\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = scaler.fit_transform(test[numerical_features])\n",
    "\n",
    "print(\"standardization applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 244)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 244)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Corr and MI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features **Mutual Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train.SalePrice\n",
    "# train_numerical = train.select_dtypes(include=[\"int64\", \"float64\"]).columns.drop(\"SalePrice\", errors=\"ignore\")\n",
    "# mutual_df = train[train_numerical]\n",
    "# mutual_info = mutual_info_regression(mutual_df.fillna(0), y, random_state=1)\n",
    "# mutual_info = pd.Series(mutual_info)\n",
    "# mutual_info.index = mutual_df.columns\n",
    "\n",
    "# #define threshold using\n",
    "# # mi_threshold = 0.01  # Drop bottom 0.01 MI features\n",
    "\n",
    "# mi_threshold = mutual_info.quantile(0.20)  # Drop bottom 0.01 MI features\n",
    "\n",
    "# # identify low MI features\n",
    "# low_mi_features = mutual_info[mutual_info < mi_threshold].index.tolist()\n",
    "\n",
    "# # drop them from the dataset\n",
    "# train.drop(columns=low_mi_features, inplace=True)\n",
    "# test.drop(columns=low_mi_features, inplace=True)\n",
    "\n",
    "# print(f\"Dropped {len(low_mi_features)} numerical features with MI < {mi_threshold:.4f}\")\n",
    "# print(f\"Remaining TRAIN features: {train.shape[1]}\")\n",
    "# print(f\"Dropped {len(low_mi_features)} numerical features with MI < {mi_threshold:.4f}\")\n",
    "# print(f\"Remaining TEST features: {test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Found 35 highly correlated feature pairs (above 0.8 threshold):\n",
      "\n",
      "🔹 Exterior1st_CBlock ↔ Exterior2nd_CBlock | Correlation: 1.00 | Keeping: Exterior1st_CBlock, Dropping: Exterior2nd_CBlock\n",
      "🔹 SaleType_New ↔ SaleCondition_Partial | Correlation: 0.99 | Keeping: SaleType_New, Dropping: SaleCondition_Partial\n",
      "🔹 Total_Close_Live_Area ↔ Total_usable_area | Correlation: 0.99 | Keeping: Total_usable_area, Dropping: Total_Close_Live_Area\n",
      "🔹 Quality_conditition ↔ Quality_conditition_2 | Correlation: 0.99 | Keeping: Quality_conditition_2, Dropping: Quality_conditition\n",
      "🔹 Exterior1st_VinylSd ↔ Exterior2nd_VinylSd | Correlation: 0.98 | Keeping: Exterior2nd_VinylSd, Dropping: Exterior1st_VinylSd\n",
      "🔹 Exterior1st_CemntBd ↔ Exterior2nd_CmentBd | Correlation: 0.97 | Keeping: Exterior1st_CemntBd, Dropping: Exterior2nd_CmentBd\n",
      "🔹 Exterior1st_MetalSd ↔ Exterior2nd_MetalSd | Correlation: 0.97 | Keeping: Exterior1st_MetalSd, Dropping: Exterior2nd_MetalSd\n",
      "🔹 GarageQual ↔ GarageCond | Correlation: 0.96 | Keeping: GarageQual, Dropping: GarageCond\n",
      "🔹 GarageCond ↔ GarageType_NA | Correlation: 0.95 | Keeping: GarageCond, Dropping: GarageType_NA\n",
      "🔹 GarageQual ↔ GarageType_NA | Correlation: 0.94 | Keeping: GarageQual, Dropping: GarageType_NA\n",
      "🔹 Total_usable_area ↔ Area_Quality_Indicator | Correlation: 0.93 | Keeping: Area_Quality_Indicator, Dropping: Total_usable_area\n",
      "🔹 Total_Close_Live_Area ↔ Area_Quality_Indicator | Correlation: 0.92 | Keeping: Area_Quality_Indicator, Dropping: Total_Close_Live_Area\n",
      "🔹 Area_Quality_Indicator ↔ Area_Qual_Cond_Indicator | Correlation: 0.92 | Keeping: Area_Quality_Indicator, Dropping: Area_Qual_Cond_Indicator\n",
      "🔹 SalePrice ↔ Area_Quality_Indicator | Correlation: 0.92 | Keeping: SalePrice, Dropping: Area_Quality_Indicator\n",
      "🔹 GarageCars ↔ GarageArea | Correlation: 0.89 | Keeping: GarageCars, Dropping: GarageArea\n",
      "🔹 MiscVal ↔ MiscFeature_Gar2 | Correlation: 0.89 | Keeping: MiscVal, Dropping: MiscFeature_Gar2\n",
      "🔹 Exterior1st_HdBoard ↔ Exterior2nd_HdBoard | Correlation: 0.89 | Keeping: Exterior1st_HdBoard, Dropping: Exterior2nd_HdBoard\n",
      "🔹 2ndFlrSF ↔ Number_of_floors | Correlation: 0.88 | Keeping: 2ndFlrSF, Dropping: Number_of_floors\n",
      "🔹 GrLivArea ↔ Total_Close_Live_Area | Correlation: 0.87 | Keeping: Total_Close_Live_Area, Dropping: GrLivArea\n",
      "🔹 Total_usable_area ↔ Area_Qual_Cond_Indicator | Correlation: 0.87 | Keeping: Area_Qual_Cond_Indicator, Dropping: Total_usable_area\n",
      "🔹 GrLivArea ↔ Total_usable_area | Correlation: 0.87 | Keeping: Total_usable_area, Dropping: GrLivArea\n",
      "🔹 OverallQual ↔ Area_Quality_Indicator | Correlation: 0.86 | Keeping: Area_Quality_Indicator, Dropping: OverallQual\n",
      "🔹 MSZoning_FV ↔ Neighborhood_Somerst | Correlation: 0.86 | Keeping: Neighborhood_Somerst, Dropping: MSZoning_FV\n",
      "🔹 Exterior1st_Wd Sdng ↔ Exterior2nd_Wd Sdng | Correlation: 0.86 | Keeping: Exterior2nd_Wd Sdng, Dropping: Exterior1st_Wd Sdng\n",
      "🔹 SalePrice ↔ Area_Qual_Cond_Indicator | Correlation: 0.85 | Keeping: SalePrice, Dropping: Area_Qual_Cond_Indicator\n",
      "🔹 Total_Close_Live_Area ↔ Area_Qual_Cond_Indicator | Correlation: 0.85 | Keeping: Area_Qual_Cond_Indicator, Dropping: Total_Close_Live_Area\n",
      "🔹 Exterior1st_AsbShng ↔ Exterior2nd_AsbShng | Correlation: 0.85 | Keeping: Exterior1st_AsbShng, Dropping: Exterior2nd_AsbShng\n",
      "🔹 GrLivArea ↔ TotRmsAbvGrd | Correlation: 0.83 | Keeping: GrLivArea, Dropping: TotRmsAbvGrd\n",
      "🔹 SalePrice ↔ Total_usable_area | Correlation: 0.83 | Keeping: SalePrice, Dropping: Total_usable_area\n",
      "🔹 SalePrice ↔ Total_Close_Live_Area | Correlation: 0.83 | Keeping: SalePrice, Dropping: Total_Close_Live_Area\n",
      "🔹 RoofStyle_Flat ↔ RoofMatl_Tar&Grv | Correlation: 0.82 | Keeping: RoofStyle_Flat, Dropping: RoofMatl_Tar&Grv\n",
      "🔹 2ndFlrSF ↔ HouseStyle_2Story | Correlation: 0.81 | Keeping: 2ndFlrSF, Dropping: HouseStyle_2Story\n",
      "🔹 GrLivArea ↔ Area_Quality_Indicator | Correlation: 0.81 | Keeping: Area_Quality_Indicator, Dropping: GrLivArea\n",
      "🔹 TotalBsmtSF ↔ 1stFlrSF | Correlation: 0.81 | Keeping: TotalBsmtSF, Dropping: 1stFlrSF\n",
      "🔹 TotalBsmtSF ↔ Total_Close_Live_Area | Correlation: 0.80 | Keeping: Total_Close_Live_Area, Dropping: TotalBsmtSF\n",
      "\n",
      "✅ Dropped 35 highly correlated features to reduce redundancy.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train.columns = train.columns.str.strip()\n",
    "test.columns = test.columns.str.strip()\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = train.corr()\n",
    "\n",
    "# Set a threshold for high correlation\n",
    "correlation_threshold = 0.8  \n",
    "\n",
    "# Select upper triangle of correlation matrix (to avoid duplicate pairs)\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find pairs of highly correlated features\n",
    "highly_correlated_pairs = []\n",
    "for col in upper_triangle.columns:\n",
    "    for row in upper_triangle.index:\n",
    "        if upper_triangle.loc[row, col] > correlation_threshold:\n",
    "            highly_correlated_pairs.append((row, col, upper_triangle.loc[row, col]))\n",
    "\n",
    "# Sort pairs by correlation value (descending order)\n",
    "highly_correlated_pairs = sorted(highly_correlated_pairs, key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "# Display the highly correlated feature pairs\n",
    "print(f\"\\n🔍 Found {len(highly_correlated_pairs)} highly correlated feature pairs (above {correlation_threshold} threshold):\\n\")\n",
    "for feature1, feature2, corr_value in highly_correlated_pairs:\n",
    "    # Compare their correlation with SalePrice\n",
    "    corr_feature1 = abs(correlation_matrix.loc[feature1, \"SalePrice\"])\n",
    "    corr_feature2 = abs(correlation_matrix.loc[feature2, \"SalePrice\"])\n",
    "    \n",
    "    # Select the one with the highest correlation to SalePrice\n",
    "    feature_to_keep = feature1 if corr_feature1 >= corr_feature2 else feature2\n",
    "    feature_to_drop = feature2 if corr_feature1 >= corr_feature2 else feature1\n",
    "    \n",
    "    print(f\"🔹 {feature1} ↔ {feature2} | Correlation: {corr_value:.2f} | Keeping: {feature_to_keep}, Dropping: {feature_to_drop}\")\n",
    "\n",
    "# Extract the unique highly correlated features\n",
    "correlated_features = list(set(sum([[f1, f2] for f1, f2, _ in highly_correlated_pairs], [])))\n",
    "\n",
    "# ✅ Drop highly correlated features from train & test datasets\n",
    "train.drop(columns=[feature_to_drop for _, feature_to_drop, _ in highly_correlated_pairs], inplace=True)\n",
    "test.drop(columns=[feature_to_drop for _, feature_to_drop, _ in highly_correlated_pairs], inplace=True)\n",
    "\n",
    "print(f\"\\n✅ Dropped {len(highly_correlated_pairs)} highly correlated features to reduce redundancy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #extract target before applying PCA\n",
    "# y_train = train[\"SalePrice\"]  \n",
    "# X_train = train.drop(columns=[\"SalePrice\"])  \n",
    "# X_test = test.copy()  \n",
    "\n",
    "# #apply PCA (Retain 98% variance)\n",
    "# pca = PCA(n_components=0.98)  \n",
    "# X_train_pca = pca.fit_transform(X_train)  \n",
    "# X_test_pca = pca.transform(X_test)  \n",
    "\n",
    "# #convert PCA output back to DataFrame\n",
    "# pca_columns = [f\"PCA_{i+1}\" for i in range(X_train_pca.shape[1])]\n",
    "# X_train_pca = pd.DataFrame(X_train_pca, index=X_train.index, columns=pca_columns)\n",
    "# X_test_pca = pd.DataFrame(X_test_pca, index=X_test.index, columns=pca_columns)\n",
    "\n",
    "# #reattach `SalePrice` to `train_pca`\n",
    "# X_train_pca[\"SalePrice\"] = y_train.values  \n",
    "\n",
    "# # #save processed datasets\n",
    "# # X_train_pca.to_csv(\"train_pca.csv\", index=False)\n",
    "# # X_test_pca.to_csv(\"test_pca.csv\", index=False)\n",
    "# train = X_train_pca\n",
    "# test = X_test_pca\n",
    "# print(f\"✅ PCA completed! New train shape: {X_train_pca.shape}, test shape: {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(0, \"Id\", train_ID)\n",
    "test.insert(0, \"Id\", test_ID)\n",
    "train.columns = train.columns.str.strip()\n",
    "test.columns = test.columns.str.strip()\n",
    "# # save processed datasets\n",
    "train.to_csv(\"train_simp_fixedOrdinal_FE.csv\", index=False)\n",
    "test.to_csv(\"test_simp_fixedOrdinal_FE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train shape: (1452, 223), test shape: (1459, 222)\n"
     ]
    }
   ],
   "source": [
    "print(f\"New train shape: {train.shape}, test shape: {test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
